"""
This module contains features related to outputs generated by a model.

The main responsibilities are data structures for holding such outputs, and code to translate outputs into readable
strings.
"""

from typing import List, Union

import xnmt.vocabs as vocabs
from xnmt.persistence import Serializable, serializable_init

class OutputProcessor(object):
  def process(self, s: str) -> str:
    """
    Produce a string-representation of an output.

    Args:
      s: string to be processed

    Returns:
      post-processed string
    """
    raise NotImplementedError("must be implemented by subclasses")

  @staticmethod
  def get_output_processor(spec: Union[str, List['OutputProcessor']]) -> List['OutputProcessor']:
    if isinstance(spec, str):
      procs = []
      for spec_item in spec.split(","):
        if spec_item == "none":
          continue
        elif spec_item == "join-char":
          procs.append(JoinCharTextOutputProcessor())
        elif spec == "join-bpe":
          procs.append(JoinBpeTextOutputProcessor())
        elif spec == "join-piece":
          procs.append(JoinPieceTextOutputProcessor())
      return procs
    else:
      return spec


class PlainTextOutputProcessor(OutputProcessor, Serializable):
  """
  This output processor does nothing and exists only for backward compatibility.
  # TODO: remove eventually.
  """
  yaml_tag = "!PlainTextOutputProcessor"
  def process(self, s: str) -> str:
    return s


class JoinCharTextOutputProcessor(OutputProcessor, Serializable):
  """
  Assumes a single-character vocabulary and joins them to form words.

  Per default, double underscores '__' are treated as word separating tokens.
  """
  yaml_tag = "!JoinCharTextOutputProcessor"
  @serializable_init
  def __init__(self, space_token: str = "__") -> None:
    self.space_token = space_token

  def process(self, s: str) -> str:
    return s.replace(" ", "").replace(self.space_token, " ")


class JoinBpeTextOutputProcessor(OutputProcessor, Serializable):
  """
  Assumes a bpe-based vocabulary and outputs the merged words.

  Per default, the '@' postfix indicates subwords that should be merged
  """
  yaml_tag = "!JoinBpeTextOutputProcessor"
  @serializable_init
  def __init__(self, merge_indicator: str = "@@") -> None:
    self.merge_indicator_with_space = merge_indicator + " "

  def process(self, s: str) -> str:
    return s.replace(self.merge_indicator_with_space, "")


class JoinPieceTextOutputProcessor(OutputProcessor, Serializable):
  """
  Assumes a sentence-piece vocabulary and joins them to form words.

  Space_token could be the starting character of a piece per default, the u'\u2581' indicates spaces
  """
  yaml_tag = "!JoinPieceTextOutputProcessor"
  @serializable_init
  def __init__(self, space_token: str = "\u2581") -> None:
    self.space_token = space_token

  def process(self, s: str) -> str:
    return s.replace(" ", "").replace(self.space_token, " ").strip()


class DependencyLeavesOutputProcessor(OutputProcessor, Serializable):
  yaml_tag = "!DependencyLeavesOutputProcessor"
  @serializable_init
  def __init__(self, string_processor:OutputProcessor=None):
    self.string_processor = string_processor

  def process(self, rnng_sent) -> str:
    tokens = [rnng_sent.value_vocab[node.value] for node in self._get_nodes(rnng_sent.graph)]
    i = -1
    while -(i+1) < len(tokens) and tokens[i] == vocabs.Vocab.ES_STR:
      i += 1
    tokens = tokens[:-(i+1)]
    sent_str = " ".join(tokens)
    if self.string_processor is not None:
      return self.string_processor.process(sent_str)
    else:
      return sent_str

  def _get_nodes(self, graph):
    return graph.iter_nodes()


class SyntaxLeavesOutputProcessor(DependencyLeavesOutputProcessor, Serializable):
  yaml_tag = "!SyntaxLeavesOutputProcessor"
  @serializable_init
  def __init__(self, string_processor:OutputProcessor=None):
    self.string_processor = string_processor

  def _get_nodes(self, graph):
    return [graph[x] for x in graph.leaves()]
