# A standard training run, should almost never break
simult: !Experiment
  exp_global: !ExpGlobal
    default_layer_dim: 64
  model: !SimultaneousTranslator
    src_reader: !PlainTextReader
      vocab: !Vocab {vocab_file: examples/data/head.en.vocab}
    trg_reader: !PlainTextReader
      vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}
  train: &my_train !SimpleTrainingRegimen
    run_for_epochs: 2
    src_file: examples/data/head.ja
    trg_file: examples/data/head.en
    dev_tasks: &my_dev
      - !AccuracyEvalTask
        eval_metrics: bleu
        src_file: examples/data/head.en
        ref_file: examples/data/head.ja
        hyp_file: test/tmp/{EXP}.test_hyp
        inference: &my_inference !AutoRegressiveInference {search_strategy: !BeamSearch {beam_size: 5}}
      - !LossEvalTask
        src_file: examples/data/head.en
        ref_file: examples/data/head.ja
  evaluate: &my_evaluate
    - !AccuracyEvalTask
      eval_metrics: bleu
      src_file: examples/data/head.en
      ref_file: examples/data/head.ja
      hyp_file: test/tmp/{EXP}.test_hyp
      inference: *my_inference

simult_learn: !Experiment
  exp_global: !ExpGlobal
    default_layer_dim: 64
  model: !SimultaneousTranslator
    src_reader: !PlainTextReader {vocab: !Vocab {vocab_file: examples/data/head.en.vocab}}
    trg_reader: !PlainTextReader {vocab: !Vocab {vocab_file: examples/data/head.ja.vocab}}
    policy_learning: !PolicyGradient
      input_dim: 192
    logger: !SimultLogger {}
  train: !SimpleTrainingRegimen
    batcher: !SrcBatcher {batch_size: 2}
    run_for_epochs: 2
    dev_tasks: *my_dev
    src_file: examples/data/head.en
    trg_file: examples/data/head.ja
    loss_calculator: !PolicyReinforceLoss {}
  evaluate: *my_evaluate
